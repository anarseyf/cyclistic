---
#output: pdf_document
output: rmarkdown::github_document
always_allow_html: yes
---

```{r packages, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

packages <- c(
  "tidyr", "knitr", "ggplot2", "ggmap", "gridExtra", "ggthemes",
  "maps", "tibble", "ggnewscale", "kableExtra", "tinytex", "extrafont", "fontcm"
)
install.packages(setdiff(packages, rownames(installed.packages())),
  repos = "http://cran.us.r-project.org"
)

library(ggplot2)
library(ggmap)
library(maps)
library(dplyr)
library(tidyr)
library(knitr)
library(tibble)
library(ggnewscale)
library(kableExtra)
library(gridExtra)
library(grid)
library(scales)
library(extrafont)
library(fontcm)
library(ggthemes)

font_install("fontcm")
loadfonts()
```

```{r theme}

theme_set(theme_minimal(
  base_family = "Times",
))
theme_update(
  axis.title = element_blank(),
  legend.position = "none",
  strip.background = element_rect(fill = "white", color = NA),
  strip.text = element_text(size = 11),
  axis.text = element_text(size = 11),
  axis.line = element_line(size = 0.25)
)

colors_IS_MEMBER <- scale_color_manual(values = c("darkred", "darkgreen"))

colors_stations_diff <- scale_color_steps(
  low = "#ffff17", high = "#e90505", na.value = "#000000", aesthetics = c("fill", "color")
)

theme_no_axis_labels <- theme(axis.text = element_blank())
```

```{r functions, echo=FALSE}

kable_custom <- function(data, full_width = FALSE, ...) {
  kbl(
    data,
    booktabs = TRUE,
    format.args = list(big.mark = ","),
    align = c("l", rep("r", ncol(data) - 1)),
    ...
  ) %>%
    kable_styling(
      # position = "left",
      latex_options = c("HOLD_position"),
      full_width = full_width
    )
}

bold_larger_fn <- function(x) {
  cell_spec(x, italic = ifelse(x == max(x), TRUE, FALSE))
}

weekday_ticks <- function() {
  function(x) {
    weekday_names
  }
}

hour_ticks <- function() {
  function(x) {
    lapply(x, to_readable_hour)
  }
}

to_readable_hour <- function(h) {
  n <- as.numeric(h)
  if (n == 0) {
    return("12am")
  }
  if (n == 12) {
    return("noon")
  }

  am_pm <- ifelse(n < 12, "am", "pm")
  if (n > 12) {
    n <- n - 12
  }
  return(paste(c(n, am_pm), collapse = ""))
}

member_labeller <- function(v) {
  ifelse(v == "true", "Member", "Casual")
}

weekday_labeller <- function(v) {
  weekday_names[as.numeric(v)]
}
```

```{r data imports}
agg_daily <- read.csv("./datasets/agg_daily_duration_count.csv")
agg_hourly <- read.csv("./datasets/agg_hourly_status.csv")
agg_monthly <- read.csv("./datasets/agg_monthly_status.csv")
agg_weekly_status <- read.csv("./datasets/agg_weekly_status.csv")
wx_correlations <- read.csv("./datasets/wx_correlations.csv")

agg_daily_trips_weather <- read.csv("./datasets/agg_daily_trips_weather.csv")
agg_daily_trips_weather$day <- as.Date(agg_daily_trips_weather$day)

agg_weekly_weather <- read.csv("./datasets/agg_weekly_weather.csv")
agg_weekly_weather$week_start <- as.Date(agg_weekly_weather$week_start)

stations_diff <- read.csv("./datasets/stations_diff_june.csv") %>% arrange(diff)

weekday_names <- c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")
```

# Cyclistic

- **Anar Seyf** | anar.seyf@gmail.com
- Capstone project | Google Data Analytics course #8 | Coursera
- October 2021
- Source code: [github.com/anarseyf/cyclistic](https://github.com/anarseyf/cyclistic)

---

## Introduction

This report is the capstone project for the Google Data Analytics professional certificate on Coursera [**[1]**](#links). The starting point is data from Cyclistic, a bike-sharing company which operates a network of classic and electric bicycles and docking stations in Chicago. The goal is to understand usage patterns between **Casual** riders (those who pay for single rides or day passes) and **Members** (those who purchased an annual membership), and to provide recommendations to the Cyclistic marketing team on how to convert casual riders into members.

---

## Data

Our main dataset contains individual ride records over a twelve-month period—October 2020 to September 2021, inclusive—provided in monthly .csv files [**[2]**](#links). This amounts to over 5 million rows with these columns:

* unique ride ID;
* status (member or casual);
* start and end time;
* start and end docking station (ID and name);
* start and end latitude/longitude;
* bicycle type (classic, docked, electric).

The individual records are aggregated into hourly, daily, and weekly tables, and grouped by status (member vs. casual). For example, the daily aggregates table consists of 730 entries (365 for Members and Casual riders each) with columns for average daily ride count and average duration.

See [**Appendix**](#appendix) for details on tools used and data cleanup steps.

---

## Analysis

### 1. Members ride more often, casual users ride for longer.

An average ride is about **14 minutes** long for Members and **28 minutes** long for Casual riders. Members make an average of **7,479** rides per day, compared to **6,362** for Casual riders. (The number of distinct riders is unavailable in the data, so we can only refer to the overall groups. Daily totals can provide a rough approximation, but only within the order of magnitude.) 

Ride volume is lowest in February and highest in July-August. Casual ride volume exceeds that of Members in the summer months only.

```{r, eval=TRUE}

wide <- agg_monthly %>%
  select(status, month_start, avg_count) %>%
  spread(month_start, avg_count)

month_starts <- colnames(wide)[2:13]
colnames(wide) <- c(" ", months(as.Date(month_starts), abbreviate = TRUE))

wide[, -1] <- round(wide[, -1])

text <- "(In this table and in Table 3, the larger of the two numbers for each month is in italics.)"

wide %>%
  format(big.mark = ",") %>%
  mutate(across(Oct:Sep, bold_larger_fn)) %>%
  kable_custom(
    full_width = TRUE,
    escape = FALSE,
    caption = "Average daily number of rides"
  ) %>%
  footnote(
    general_title = "",
    general = text
  )
```

Ride duration is nearly flat for Members throughout the year; for Casual riders it increases by a few minutes in the summer months.

```{r, eval=TRUE}

wide <- agg_monthly %>%
  select(status, month_start, duration) %>%
  spread(month_start, duration)

month_starts <- colnames(wide)[2:13]
colnames(wide) <- c(" ", months(as.Date(month_starts), abbreviate = TRUE))

wide[, -1] <- round(wide[, -1])

text <- "February has an abnormal spike in ride duration. It may be partly due to low ride volume and thus higher variance in the data, but is otherwise not readily explainable here. It is likely to be weather-related, perhaps due to difficulties of reaching a docking station."

wide %>%
  kable_custom(caption = "Average ride duration (minutes)") %>%
  footnote(general = text, threeparttable = TRUE)
```

### 2. Members ride all week, casual riders prefer weekends.

Ride volume remains nearly flat for Members through the week, reducing only on Sundays. Casual users do the most riding over the weekend, peaking on Saturdays.

```{r, eval=TRUE}

wide <- agg_weekly_status %>%
  select(-avg_duration) %>%
  spread(dayofweek, avg_count)

colnames(wide) <- c(" ", weekday_names)

wide %>%
  format(big.mark = ",") %>%
  mutate(across(Mon:Sun, bold_larger_fn)) %>%
  kable_custom(
    escape = FALSE,
    caption = "Average daily number of rides"
  )
```

```{r, eval=TRUE}

wide <- agg_weekly_status %>%
  select(-avg_count) %>%
  spread(dayofweek, avg_duration)

colnames(wide) <- c(" ", weekday_names)

wide %>% kable_custom(caption = "Average ride duration (minutes)")
```

#### Hourly heatmap

A more detailed view of the data from _Table 3_. The Monday–Friday pattern for Members closely matches standard working hours; note especially the peak around 4–5pm. Weekend patterns are closer between the two groups, apart from volume; note, for example, Saturday evening activity spilling over into early morning on Sunday.

```{r, fig.width=8, fig.height=3, out.width='90%', eval=TRUE}

agg_hourly %>%
  ggplot(aes(
    x = dayofweek,
    y = factor(hour, levels = unique(rev(hour))),
    fill = COUNT
  )) +
  geom_tile(color = "grey", position = position_dodge(width = 0.1)) +
  scale_fill_viridis_c(option = "viridis", trans = pseudo_log_trans()) +
  # scale_fill_gradientn(colors = heat.colors(20), trans = pseudo_log_trans()) +
  # scale_fill_gradient(
  #   low = "black", high = "yellow",
  #   trans = pseudo_log_trans()
  # ) +
  scale_x_continuous(labels = weekday_ticks(), breaks = 1:7, expand = c(0, 0)) +
  scale_y_discrete(labels = hour_ticks(), breaks = seq(0, 23, 4)) +
  facet_wrap(~IS_MEMBER, labeller = labeller(IS_MEMBER = member_labeller))
```

### 3. Seasons affect ride volume, but average duration remains stable.

This section uses the Chicago daily weather dataset from NOAA [**[3]**](#links).

The following chart plots one year of ride data, aggregated by week, against weather for that week: average daily air temperature (background colors), cumulative rain, and cumulative snow.

```{r, fig.width=10, fig.height=3, eval=TRUE}

month_labels <- function(x) {
  months(x, abbreviate = TRUE)
}

df <- agg_weekly_weather %>%
  mutate(is_member = ifelse(is_member, "Member", "Casual"))

df %>%
  ggplot(aes(x = week_start)) +
  geom_bar(aes(y = Inf, fill = avg_temp),
    stat = "identity", alpha = 0.4, position = "dodge"
  ) +
  scale_fill_viridis_c(option = "inferno", name = "Temp. \u00B0C") +
  new_scale_fill() +
  # new_scale_color() +

  geom_step(aes(
    y = avg_count,
    group = is_member,
    color = is_member,
  ),
  size = 1.25,
  stat = "identity"
  ) +
  geom_point(aes(
    y = avg_count,
    group = is_member,
    color = is_member,
    fill = is_member
  ),
  shape = 22, # https://r-graphics.org/recipe-scatter-shapes#discussion-28
  # fill = "white",
  size = 2,
  stroke = 2
  ) +
  colors_IS_MEMBER +
  guides(color = guide_legend(title = ""), fill = "none") +
  scale_fill_manual(values = c("white", "darkgreen")) +

  # new_scale_fill() +
  # new_scale_color() +

  geom_point(
    data = subset(df, total_snow > 0),
    aes(y = -2000, size = total_snow / 10), shape = 23, fill = "#9b037a", alpha = 0.7,
    show.legend = FALSE
  ) +
  # guides(size = guide_legend(title = "Snow (mm)")) +
  geom_point(
    data = subset(df, total_rain > 0),
    aes(y = -1000, size = total_rain),
    color = "#2192d3", alpha = 0.7,
    show.legend = FALSE
  ) +
  scale_x_date(expand = c(0, 0), labels = month_labels, date_breaks = "months") +
  scale_y_continuous(expand = c(0, 1000)) +
  geom_vline(xintercept = as.Date("2021-01-01"), size = 0.5) +
  # labs(title = "Ride count vs. weather factors") +
  theme(
    legend.position = "right",
    axis.text = element_text(size = 13),
    plot.caption = element_text(size = 15)
  )
```

```{r, eval=TRUE}
text <- "The Pearson correlation coefficient (r) measures how strongly two sets of data are linearly correlated, from -1 (perfect negative) to 1 (perfect positive), with 0 indicating no correlation. Here, for example, ride count is negatively correlated with snow: the more snow, the fewer rides."

colnames <- c(" ", "Temperature", "Rain", "Snow", "Wind", "Temperature", "Rain", "Snow", "Wind")

wx_correlations %>%
  kable_custom(
    col.names = colnames,
    caption = "Correlation (r): ride volume vs. weather factors"
  ) %>%
  add_header_above(c(" " = 1, "Count" = 4, "Duration" = 4)) %>%
  column_spec(c(2, 6), bold = TRUE) %>%
  footnote(general = text, threeparttable = TRUE)
```

Table 5 shows that the number of rides on a given day is strongly—almost perfectly—correlated with **air temperature** for both groups; duration, on the other hand, shows almost no correlation. The following plots help illustrate this relationship. Each circle represents one day; 365 circles for each plot; the diagonal lines represent best linear fit and confidence intervals.

```{r, fig.height=2, eval=TRUE}

alpha <- 0.3

temp_breaks <-
  scale_x_continuous(breaks = c(-10, 0, 10, 20))

duration_breaks <- scale_y_continuous(breaks = c(20, 30, 40))

scatterplot <- agg_daily_trips_weather %>%
  filter(AVG_DURATION < 100) # removes 1 data point — 16 Feb 2021

p1 <- scatterplot %>%
  ggplot(
    aes(x = temp_avg, y = COUNT, color = IS_MEMBER)
  ) +
  colors_IS_MEMBER +
  geom_point(alpha = alpha) +
  geom_smooth(method = "lm") +
  geom_vline(xintercept = 0, linetype = "dotted", size = 0.5) +
  temp_breaks +
  facet_wrap(~IS_MEMBER, labeller = labeller(IS_MEMBER = member_labeller)) +
  labs(caption = "Air temperature (\u00B0C) vs. number of rides") +
  guides(color = "none") +
  theme(
    axis.text = element_text(size = 9),
    plot.caption = element_text(size = 10)
  )

p2 <- scatterplot %>%
  ggplot(aes(x = temp_avg, y = AVG_DURATION, color = IS_MEMBER)) +
  colors_IS_MEMBER +
  geom_point(alpha = alpha) +
  geom_smooth(method = "lm") +
  geom_vline(xintercept = 0, linetype = "dotted", size = 0.5) +
  temp_breaks +
  duration_breaks +
  facet_wrap(~IS_MEMBER, labeller = labeller(IS_MEMBER = member_labeller)) +
  labs(
    caption = "Air temperature (\u00B0C) vs. ride duration (minutes)",
  ) +
  guides(color = "none") +
  theme(
    axis.text = element_text(size = 9),
    plot.caption = element_text(size = 10)
  )

grid.arrange(p1, p2, nrow = 1)
```

**Rain** is more ambiguous: correlation is close to 0. Does this mean bike-share users in Chicago are indifferent to rain? The more plausible explanation is that we are at the limits of this dataset. In the 12-month period, 256 days had no recorded rain, and only 16 days had half an inch or more; on those days, Members rode for 4% less total time, and Casual riders 6% more, than on days with less rain. In other words, it did not rain enough to make the relationship clear.

These distributions confirm an observation from section 1: average ride duration remains nearly flat (more so for Members), but ride volume can vary significantly.

### 4. Geographical patterns are distinct across the week.

The source dataset contains 1288 distinct docking stations. 85% of all rides have both a start and an end station specified; in this section we focus on that subset only (the other 15% start and/or end outside of a docking station). To prevent seasonal trends from complicating the picture, the data is further filtered to four weeks in the summer (June 1st—June 28th).

### Friday morning (8–10am)

```{r, eval=TRUE}

index <- stations_diff$diff > 0
chicago_long_lat <- c(lon = -87.63, lat = 41.9)

# TODO — try log_trans scale instead?

stations_diff$log_diff[index] <- log10(stations_diff$diff[index])
stations_diff$log_diff[stations_diff$diff <= 0] <- NA

map12 <- get_map(location = chicago_long_lat, zoom = 12, maptype = "toner-lite")

alpha <- 0.7
```

This plot isolates daily and weekly patterns using a heatmap of station usage.

```{r, fig.height=3, eval=TRUE}

heatmap_large <- stations_diff %>%
  filter(dayofweek == 5) %>%
  filter(hour == 8 | hour == 9)

ggmap(map12) +
  # ggplot() +
  geom_point(
    data = heatmap_large,
    aes(x = lng, y = lat, color = log_diff),
    alpha = alpha,
    size = 3,
    shape = 19,
    # color = "#313131"
  ) +
  colors_stations_diff +
  theme_no_axis_labels +
  facet_wrap(~is_member, labeller = labeller(is_member = member_labeller)) +
  theme(axis.line = element_blank())
```

Each dot represents a bike docking station. The metric is: _count(rides ended) – count(rides started)_, for each station, within one hour. Dark dots indicate more starts than ends, and thus an _outflow_ of bike traffic; colored dots are stations where more rides have ended than started, or an _inflow_ of traffic (redder colors indicate more arrivals, on a log scale).

In other words: _clusters of "hot" stations indicate areas that people are cycling into_.

Let's look at the same pattern across the week (again, these are totals across a four-week time window).

### Morning (8–9am)
```{r, fig.height=2, eval=TRUE}
heatmap1 <- stations_diff %>%
  filter(hour == 8)

ggmap(map12) +
  # ggplot() +
  geom_point(
    data = heatmap1,
    aes(x = lng, y = lat, color = log_diff),
    alpha = alpha,
    size = 2,
    shape = 19,
    # color = "#313131"
  ) +
  colors_stations_diff +
  theme_no_axis_labels +
  facet_grid(is_member ~ dayofweek, labeller = labeller(dayofweek = weekday_labeller, is_member = member_labeller)) +
  theme(axis.line = element_blank())
```

A distinct weekday pattern emerges. Apart from ride counts (as mentioned in section 1, Members make more total rides than Casual users), the "fingerprints" look similar for the two groups. During the work week the flow is into the center of the city; on weekends the flow is more dispersed.

### Afternoon (4–5pm)
```{r, fig.height=2, eval=TRUE}
heatmap2 <- stations_diff %>%
  filter(hour == 16)

ggmap(map12) +
  # ggplot() +
  geom_point(
    data = heatmap2,
    aes(x = lng, y = lat, color = log_diff),
    alpha = alpha,
    size = 2,
    shape = 19,
  ) +
  colors_stations_diff +
  theme_no_axis_labels +
  facet_grid(is_member ~ dayofweek, labeller = labeller(dayofweek = weekday_labeller, is_member = member_labeller)) +
  theme(axis.line = element_blank())
```

In the afternoon the volume of riding spikes (see also the heatmap in section 2), and also disperses away from center.

---

## Conclusions

### Members use the service as a utility, Casual riders as more of a luxury.

Riding a Cyclistic bike is an always-available option to members at no additional cost. If a bike is available nearby, starting a ride is a non-issue. Conversely, casual riders face an additional financial "barrier to entry" before each ride (or each day). The distinctions in usage (both ride duration and number of rides) are likely explained mainly by this distinction. A member can use the service for running small errands or commuting to work. Casual users have to be more selective in their use.

### The two groups' usage patterns overlap.

Weekly and geographical usage patterns for Members and Casual riders have enough similarities to suggest they represent essentially the same pool of people, in terms of their travel goals. Both groups ride more in late afternoon (presumably when their work day ends); both groups ride a lot on Saturday afternoon; and so on.

---

## Recommendations

How to convert existing casual riders into members?

### 1. Nudge casual riders toward memberships with free trials

Make it easy for casual users to consider Cyclistic as a regular transportation option. Consider removing the main barriers to entry by allowing them to temporarily gain membership privileges—automatically and free of charge. For example, turn a single pass into a free weekly or monthly trial of the membership, send out a promotion for such a trial, or advertise specific days when these trials will be offered.

### 2. Address specific modes of riding

This analysis suggests the presence of several modes of riding for each group. The next step is to drill down further and tease out specific modes and use cases, as well as those currently not feasible or not considered. Examples:

- Riding to major sporting events on weekends and avoiding parking problems
- Riding every day during a specific time window
- Riding longer distances (does the electric bike hold enough charge?)
- Riding combined with other modes of transport

### 3. Understand obstacles to regular riding and help remove them

Find out if a subset of Casual riders want to become members, but cannot due to factors other than cost. Does their neighborhood lack docking stations? Do they need help with planning a safe route? Consider working with the city on expanding cycling routes and making cycling safer.

---

## Appendix {#appendix}

### Limitations and scope

The available dataset does not contain any individual ridership data or any information on cohorts; seasonal trends could be in part attributable to membership growth.

Factors out of scope for this study: bike types; external factors beyond weather (natural disasters, sporting events, road closures); pricing; individual user profiles; year-over-year trends; other modes of transport; neighborhood specifics.

### Data cleanup {#cleaning}

The following entries were removed:

* Entries with ride duration of less than 1 minute or negative (end time before start time);
* Entries with ride duration of over 24 hours;
* A few entries that appeared to be test data;
* (for the plots in section 4 only) A single outlier, 16 Feb 2021, with an abnormally high average duration.

The cleaned result contained 5,051,830 entries, down from 5,136,261 in the source.

Heatmaps use logarithmic scales to present values differing by several orders of magnitude.

### Tools used {#tools}

1. **Terminal (zsh)**
   - Download and unzip source data files, calculate lines, concatenate into a single file.

2. **Google Sheets**
   - Initial exploration of a small subset of the data; sample pivot tables. Google Sheets has a limitation of 5 million _cells_ (not rows) per sheet, so analyzing the full dataset there was not realistic. 

3. **BigQuery** and **SQL**
   - Loaded the full dataset into Google Cloud Platform's BigQuery;  analyzed and built aggregates using SQL.

4. **R programming language**
   - Plot generation and final data manipulation.

5. **rmarkdown** and **knitr**
   - Compilation of the report as PDF and HTML.

### Links {#links}

1. Coursera — Google Data Analytics
   - https://www.coursera.org/professional-certificates/google-data-analytics
1. Source data from Divvy
   - https://divvy-tripdata.s3.amazonaws.com/index.html
1. NOAA Chicago daily weather. Collected at O'Hare Airport.
   - https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094846/detail
1. BigQuery
   - https://cloud.google.com/bigquery
1. Pearson correlation coefficient
   - https://en.wikipedia.org/wiki/Pearson_correlation_coefficient